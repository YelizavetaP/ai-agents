{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from IPython.display import Image, display\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=os.getenv(\"LLM_MODEL\", \"gpt-4o-mini\"),\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calcium CT score and high cholesterol relationship\n",
      "This query seeks to understand the connection between coronary artery calcium scoring and cholesterol levels, both of which are important factors in assessing cardiovascular health.\n"
     ]
    }
   ],
   "source": [
    "# Schema for structured output\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class SearchQuery(BaseModel):\n",
    "    search_query: str = Field(None, description=\"Query that is optimized web search.\")\n",
    "    justification: str = Field(\n",
    "        None, justification=\"Why this query is relevant to the user's request.\"\n",
    "    )\n",
    "\n",
    "# Augment the LLM with schema for structured output\n",
    "structured_llm = llm.with_structured_output(SearchQuery)\n",
    "\n",
    "# Invoke the augmented LLM\n",
    "output = structured_llm.invoke(\"How does Calcium CT score relate to high cholesterol?\")\n",
    "print(output.search_query)\n",
    "print(output.justification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 2, 'b': 3},\n",
       "  'id': 'call_9evSXtgQWjN6cvywdpZFeThw',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def multiply(a: int, b: int) -> int:\n",
    "    return a * b\n",
    "\n",
    "# Augment the LLM with tools\n",
    "llm_with_tools = llm.bind_tools([multiply])\n",
    "\n",
    "# Invoke the LLM with input that triggers the tool call\n",
    "msg = llm_with_tools.invoke(\"What is 2 times 3?\")\n",
    "\n",
    "# Get the tool call\n",
    "msg.tool_calls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangGraph312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
